{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 6665954,
          "sourceType": "datasetVersion",
          "datasetId": 3546787
        }
      ],
      "dockerImageVersionId": 30527,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "notebookef25a3a454",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SwethaR1505/CAMPUS-_CODER-_PROJECT1/blob/main/notebookef25a3a454.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'pets-facial-expression-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F3546787%2F6665954%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240518%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240518T044401Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D034011b6f4ed199c4eb7a942a83b5e31ea014b45e2688e41249c9c154f16b23ec7cba3f2f0ffacd999615fdfead3ca575c1869ad121e84613d54a721f6ea9fae38de5de1e566216106630c8de7a047fa6d0b90b22159bfe4899115723e2eb6dc8700104592b609ed4d7f165eed76b87af0dbc7cc555f32fd7907ab8e985648445bf35265053ecb9dd574fad66742fb0600589bfda1ca6aab833ffb008c1757fd0c1dd8b8237c27f7afc9948c780fb970652a0521477e5c6cdeaefe9fc50762887df6aa8cb3cf9e27e3277be22bf38ab086a6e17fdafac18ba7849cac49b3a36156de76d2e933d577ea81bda5006b6599ce4c3da0d1a951d120c509075d6c4320'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "LxEXQzAUA-8Y"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Thanks for Visting this notebook and Using this dataset!\n",
        "![17045504.jpg](attachment:7000684c-1ab3-4c62-8d0a-7479f81c9348.jpg)\n",
        "<div class=\"alert alert-block alert-info\" style=\"font-size:20px; font-family:verdana;\">\n",
        "    In this notebook I have used basic CNNs to provide a baseline model for Pet's Facial expression recognition .Feel free to fork or edit the notebook.If you liked the notebook and Dataset, consider *upvoting* them. It helps other people discover them.\n",
        "</div>"
      ],
      "metadata": {
        "id": "dZVL9KzKA-8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install tensorflow keras opencv-python"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-24T17:31:24.851239Z",
          "iopub.execute_input": "2023-07-24T17:31:24.852774Z",
          "iopub.status.idle": "2023-07-24T17:31:24.857607Z",
          "shell.execute_reply.started": "2023-07-24T17:31:24.852739Z",
          "shell.execute_reply": "2023-07-24T17:31:24.856661Z"
        },
        "trusted": true,
        "id": "kQ2rJ_wYA-8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <div style=\"background-color:#fff1cc; padding: 20px;\">ðŸ“© Importing The Modules</div>"
      ],
      "metadata": {
        "id": "2Oaxu0SIA-8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
        "from IPython.display import display, Image\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2023-07-24T17:31:24.862196Z",
          "iopub.execute_input": "2023-07-24T17:31:24.862552Z",
          "iopub.status.idle": "2023-07-24T17:31:36.301Z",
          "shell.execute_reply.started": "2023-07-24T17:31:24.862499Z",
          "shell.execute_reply": "2023-07-24T17:31:36.299873Z"
        },
        "trusted": true,
        "id": "-NL-TNNVA-8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <div style=\"background-color:#fff1cc; padding: 20px;\">ðŸ“…Data Loading and Preprocessing </div>"
      ],
      "metadata": {
        "id": "Div4arUiA-8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the dataset folders\n",
        "happy_folder = \"/kaggle/input/pets-facial-expression-dataset/happy\"\n",
        "sad_folder = \"/kaggle/input/pets-facial-expression-dataset/Sad\"\n",
        "angry_folder = \"/kaggle/input/pets-facial-expression-dataset/Angry\"\n",
        "\n",
        "\n",
        "# Function to load and preprocess images\n",
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img = cv2.imread(os.path.join(folder, filename))\n",
        "        if img is not None:\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            img = cv2.resize(img, (48, 48))  # Resize to a fixed size for the model\n",
        "            images.append(img)\n",
        "    return images\n",
        "\n",
        "# Load images and labels for each emotion\n",
        "happy_images = load_images_from_folder(happy_folder)\n",
        "sad_images = load_images_from_folder(sad_folder)\n",
        "angry_images = load_images_from_folder(angry_folder)\n",
        "\n",
        "\n",
        "# Create labels for each emotion category\n",
        "happy_labels = [0] * len(happy_images)\n",
        "sad_labels = [1] * len(sad_images)\n",
        "angry_labels = [2] * len(angry_images)\n",
        "\n",
        "\n",
        "# Concatenate images and labels\n",
        "X = np.array(happy_images + sad_images + angry_images)\n",
        "y = np.array(happy_labels + sad_labels + angry_labels)\n",
        "\n",
        "# Normalize pixel values to range [0, 1]\n",
        "X = X.astype('float32') / 255.0\n",
        "\n",
        "# One-hot encode the labels\n",
        "y = np_utils.to_categorical(y, 3)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-24T17:31:36.306467Z",
          "iopub.execute_input": "2023-07-24T17:31:36.309786Z",
          "iopub.status.idle": "2023-07-24T17:31:46.850709Z",
          "shell.execute_reply.started": "2023-07-24T17:31:36.309742Z",
          "shell.execute_reply": "2023-07-24T17:31:46.849605Z"
        },
        "trusted": true,
        "id": "vgcEztvGA-8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <div style=\"background-color:#fff1cc; padding: 20px;\">ðŸ§  Training and Evaluation</div>"
      ],
      "metadata": {
        "id": "Xw1mnQj5A-8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Build the CNN model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(48, 48, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(512, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "print(model.summary())\n",
        "# Compile the model with class weights\n",
        "model.compile(loss='categorical_crossentropy', optimizer=\"Adam\", metrics=['accuracy'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-24T17:42:21.244678Z",
          "iopub.execute_input": "2023-07-24T17:42:21.24504Z",
          "iopub.status.idle": "2023-07-24T17:42:21.460282Z",
          "shell.execute_reply.started": "2023-07-24T17:42:21.24501Z",
          "shell.execute_reply": "2023-07-24T17:42:21.459507Z"
        },
        "trusted": true,
        "id": "ypzOqVi3A-8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Calculate class weights\n",
        "total_samples = len(y_train)\n",
        "class_weights = {0: total_samples / np.sum(y_train[:, 0]),\n",
        "                 1: total_samples / np.sum(y_train[:, 1]),\n",
        "                 2: total_samples / np.sum(y_train[:, 2])}\n",
        "# Train the model with class weights\n",
        "history = model.fit(X_train.reshape(-1, 48, 48, 1), y_train, batch_size=32, epochs=100, validation_split=0.1, class_weight=class_weights,verbose=0)\n",
        "\n",
        "# Evaluate the model on test data\n",
        "loss, accuracy = model.evaluate(X_test.reshape(-1, 48, 48, 1), y_test)\n",
        "losstr, accuracytr = model.evaluate(X_train.reshape(-1, 48, 48, 1), y_train)\n",
        "\n",
        "\n",
        "# Save the trained model\n",
        "model.save(\"facial_expression_model.h5\")\n"
      ],
      "metadata": {
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2023-07-24T17:50:30.498007Z",
          "iopub.execute_input": "2023-07-24T17:50:30.49838Z",
          "iopub.status.idle": "2023-07-24T17:50:43.347056Z",
          "shell.execute_reply.started": "2023-07-24T17:50:30.498345Z",
          "shell.execute_reply": "2023-07-24T17:50:43.345622Z"
        },
        "trusted": true,
        "id": "FAEcydDyA-8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Test accuracy: {accuracy*100:.2f}%\")\n",
        "print(f\"Train accuracy: {accuracytr*100:.2f}%\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-24T17:50:17.480154Z",
          "iopub.execute_input": "2023-07-24T17:50:17.481026Z",
          "iopub.status.idle": "2023-07-24T17:50:17.487117Z",
          "shell.execute_reply.started": "2023-07-24T17:50:17.480983Z",
          "shell.execute_reply": "2023-07-24T17:50:17.485949Z"
        },
        "trusted": true,
        "id": "ptxn8CVxA-8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <div style=\"background-color:#fff1cc; padding: 20px;\">ðŸŽµHyperparamter tuning</div>"
      ],
      "metadata": {
        "id": "-VV-odWtA-8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from keras.wrappers.scikit_learn import KerasClassifier\n",
        "# from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# # Function to create and compile the CNN model\n",
        "# def create_cnn_model(conv_filters_1=64, conv_filters_2=128, dense_units=512, dropout_rate=0.5):\n",
        "#     model = Sequential()\n",
        "#     model.add(Conv2D(conv_filters_1, (3, 3), activation='relu', input_shape=(48, 48, 1)))\n",
        "#     model.add(Conv2D(conv_filters_1, (3, 3), activation='relu'))\n",
        "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#     model.add(Dropout(dropout_rate))\n",
        "\n",
        "#     model.add(Conv2D(conv_filters_2, (3, 3), activation='relu'))\n",
        "#     model.add(Conv2D(conv_filters_2, (3, 3), activation='relu'))\n",
        "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#     model.add(Dropout(dropout_rate))\n",
        "\n",
        "#     model.add(Flatten())\n",
        "#     model.add(Dense(dense_units, activation='relu'))\n",
        "#     model.add(Dropout(dropout_rate))\n",
        "#     model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "#     # Compile the model with categorical_crossentropy loss\n",
        "#     model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#     return model\n",
        "\n",
        "# # Create a KerasClassifier wrapper for the CNN model\n",
        "# cnn_model = KerasClassifier(build_fn=create_cnn_model, epochs=10, batch_size=64, verbose=1)\n",
        "\n",
        "# # Define the hyperparameter space to search\n",
        "# param_grid = {\n",
        "#     'conv_filters_1': [32, 64, 128],\n",
        "#     'conv_filters_2': [64, 128, 256],\n",
        "#     'dense_units': [256, 512, 1024],\n",
        "#     'dropout_rate': [0.25, 0.5, 0.75]\n",
        "# }\n",
        "\n",
        "# # Create a RandomizedSearchCV object\n",
        "# random_search = RandomizedSearchCV(cnn_model, param_distributions=param_grid, n_iter=10, cv=3, verbose=1, random_state=42)\n",
        "\n",
        "# # Fit the RandomizedSearchCV to the data\n",
        "# random_search_result = random_search.fit(X_train.reshape(-1, 48, 48, 1), y_train)\n",
        "\n",
        "# # Print the best hyperparameters found\n",
        "# print(\"Best Parameters:\", random_search_result.best_params_)\n",
        "\n",
        "# # Retrieve the best model\n",
        "# best_model = random_search_result.best_estimator_\n",
        "\n",
        "# # Evaluate the best model on test data\n",
        "# loss, accuracy = best_model.model.evaluate(X_test.reshape(-1, 48, 48, 1), y_test)\n",
        "# print(f\"Test accuracy of the best model: {accuracy*100:.2f}%\")\n"
      ],
      "metadata": {
        "scrolled": true,
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2023-07-24T17:31:52.102979Z",
          "iopub.status.idle": "2023-07-24T17:31:52.103361Z",
          "shell.execute_reply.started": "2023-07-24T17:31:52.103172Z",
          "shell.execute_reply": "2023-07-24T17:31:52.10319Z"
        },
        "trusted": true,
        "id": "LjNbYHfpA-8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <div style=\"background-color:#fff1cc; padding: 20px;\">ðŸ˜»Testing the model on Pet's images</div>"
      ],
      "metadata": {
        "id": "xh6vftXCA-8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "# Load the saved model\n",
        "loaded_model = load_model(\"facial_expression_model.h5\")\n",
        "\n",
        "\n",
        "\n",
        "# Function to load and preprocess images\n",
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img = cv2.imread(os.path.join(folder, filename))\n",
        "        if img is not None:\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            img = cv2.resize(img, (48, 48))  # Resize to a fixed size for the model\n",
        "            images.append(img)\n",
        "    return images\n",
        "\n",
        "\n",
        "# Load a custom test image\n",
        "custom_test_image_path = \"/kaggle/input/pets-facial-expression-dataset/Angry/16924834.jpg\"\n",
        "\n",
        "custom_test_image = cv2.imread(custom_test_image_path)\n",
        "custom_test_image = cv2.cvtColor(custom_test_image, cv2.COLOR_BGR2GRAY)\n",
        "custom_test_image = cv2.resize(custom_test_image, (48, 48))\n",
        "custom_test_image = custom_test_image.astype('float32') / 255.0\n",
        "\n",
        "# Reshape the image to match the model input shape\n",
        "custom_test_image = np.expand_dims(custom_test_image, axis=0)\n",
        "custom_test_image = np.expand_dims(custom_test_image, axis=-1)\n",
        "\n",
        "# Make predictions on the custom test image\n",
        "prediction = loaded_model.predict(custom_test_image)\n",
        "prediction_prob = prediction[0]\n",
        "\n",
        "emotion_label = np.argmax(prediction[0])\n",
        "\n",
        "# Map the predicted label to emotion class\n",
        "emotion_classes = {0: 'happy', 1: 'sad', 2: 'angry'}\n",
        "predicted_emotion = emotion_classes[emotion_label]\n",
        "\n",
        "# Print the custom test image and its predicted label\n",
        "print(f\"Predicted Emotion: {predicted_emotion}\")\n",
        "print(f\"Confidence [happy, sad, angry]: {prediction_prob}\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Display the custom test image using matplotlib\n",
        "plt.imshow(custom_test_image[0, :, :, 0])\n",
        "plt.title(f\"Predicted Emotion: {predicted_emotion}\")\n",
        "plt.axis('off')  # Hide axes\n",
        "plt.show()\n",
        "\n",
        "from PIL import Image\n",
        "# Display the original custom test image using PIL\n",
        "img_pil = Image.open(custom_test_image_path)\n",
        "plt.imshow(np.array(img_pil))\n",
        "plt.title(f\"Predicted Emotion: {predicted_emotion}\")\n",
        "plt.axis('off')  # Hide axes\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-24T17:45:07.09045Z",
          "iopub.execute_input": "2023-07-24T17:45:07.091442Z",
          "iopub.status.idle": "2023-07-24T17:45:08.456384Z",
          "shell.execute_reply.started": "2023-07-24T17:45:07.091378Z",
          "shell.execute_reply": "2023-07-24T17:45:08.455478Z"
        },
        "trusted": true,
        "id": "CSlqzpEGA-8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "# Load the saved model\n",
        "loaded_model = load_model(\"facial_expression_model.h5\")\n",
        "\n",
        "\n",
        "\n",
        "# Function to load and preprocess images\n",
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img = cv2.imread(os.path.join(folder, filename))\n",
        "        if img is not None:\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            img = cv2.resize(img, (48, 48))  # Resize to a fixed size for the model\n",
        "            images.append(img)\n",
        "    return images\n",
        "\n",
        "\n",
        "# Load a custom test image\n",
        "custom_test_image_path = \"/kaggle/input/pets-facial-expression-dataset/happy/17045504.jpg\"\n",
        "\n",
        "custom_test_image = cv2.imread(custom_test_image_path)\n",
        "custom_test_image = cv2.cvtColor(custom_test_image, cv2.COLOR_BGR2GRAY)\n",
        "custom_test_image = cv2.resize(custom_test_image, (48, 48))\n",
        "custom_test_image = custom_test_image.astype('float32') / 255.0\n",
        "\n",
        "# Reshape the image to match the model input shape\n",
        "custom_test_image = np.expand_dims(custom_test_image, axis=0)\n",
        "custom_test_image = np.expand_dims(custom_test_image, axis=-1)\n",
        "\n",
        "# Make predictions on the custom test image\n",
        "prediction = loaded_model.predict(custom_test_image)\n",
        "prediction_prob = prediction[0]\n",
        "\n",
        "emotion_label = np.argmax(prediction[0])\n",
        "\n",
        "# Map the predicted label to emotion class\n",
        "emotion_classes = {0: 'happy', 1: 'sad', 2: 'angry'}\n",
        "predicted_emotion = emotion_classes[emotion_label]\n",
        "\n",
        "# Print the custom test image and its predicted label\n",
        "print(f\"Predicted Emotion: {predicted_emotion}\")\n",
        "print(f\"Confidence [happy, sad, angry]: {prediction_prob}\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Display the custom test image using matplotlib\n",
        "plt.imshow(custom_test_image[0, :, :, 0])\n",
        "plt.title(f\"Predicted Emotion: {predicted_emotion}\")\n",
        "plt.axis('off')  # Hide axes\n",
        "plt.show()\n",
        "\n",
        "from PIL import Image\n",
        "# Display the original custom test image using PIL\n",
        "img_pil = Image.open(custom_test_image_path)\n",
        "plt.imshow(np.array(img_pil))\n",
        "plt.title(f\"Predicted Emotion: {predicted_emotion}\")\n",
        "plt.axis('off')  # Hide axes\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2023-07-24T17:45:11.390635Z",
          "iopub.execute_input": "2023-07-24T17:45:11.391001Z",
          "iopub.status.idle": "2023-07-24T17:45:12.324572Z",
          "shell.execute_reply.started": "2023-07-24T17:45:11.390968Z",
          "shell.execute_reply": "2023-07-24T17:45:12.323462Z"
        },
        "trusted": true,
        "id": "LP8-F6IzA-8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "# Load the saved model\n",
        "loaded_model = load_model(\"facial_expression_model.h5\")\n",
        "\n",
        "\n",
        "\n",
        "# Function to load and preprocess images\n",
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img = cv2.imread(os.path.join(folder, filename))\n",
        "        if img is not None:\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            img = cv2.resize(img, (48, 48))  # Resize to a fixed size for the model\n",
        "            images.append(img)\n",
        "    return images\n",
        "\n",
        "\n",
        "# Load a custom test image\n",
        "custom_test_image_path = \"/kaggle/input/pets-facial-expression-dataset/Sad/4214919.jpg\"\n",
        "\n",
        "custom_test_image = cv2.imread(custom_test_image_path)\n",
        "custom_test_image = cv2.cvtColor(custom_test_image, cv2.COLOR_BGR2GRAY)\n",
        "custom_test_image = cv2.resize(custom_test_image, (48, 48))\n",
        "custom_test_image = custom_test_image.astype('float32') / 255.0\n",
        "\n",
        "# Reshape the image to match the model input shape\n",
        "custom_test_image = np.expand_dims(custom_test_image, axis=0)\n",
        "custom_test_image = np.expand_dims(custom_test_image, axis=-1)\n",
        "\n",
        "# Make predictions on the custom test image\n",
        "prediction = loaded_model.predict(custom_test_image)\n",
        "prediction_prob = prediction[0]\n",
        "\n",
        "emotion_label = np.argmax(prediction[0])\n",
        "\n",
        "# Map the predicted label to emotion class\n",
        "emotion_classes = {0: 'happy', 1: 'sad', 2: 'angry'}\n",
        "predicted_emotion = emotion_classes[emotion_label]\n",
        "\n",
        "# Print the custom test image and its predicted label\n",
        "print(f\"Predicted Emotion: {predicted_emotion}\")\n",
        "print(f\"Confidence [happy, sad, angry]: {prediction_prob}\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Display the custom test image using matplotlib\n",
        "plt.imshow(custom_test_image[0, :, :, 0])\n",
        "plt.title(f\"Predicted Emotion: {predicted_emotion}\")\n",
        "plt.axis('off')  # Hide axes\n",
        "plt.show()\n",
        "\n",
        "from PIL import Image\n",
        "# Display the original custom test image using PIL\n",
        "img_pil = Image.open(custom_test_image_path)\n",
        "plt.imshow(np.array(img_pil))\n",
        "plt.title(f\"Predicted Emotion: {predicted_emotion}\")\n",
        "plt.axis('off')  # Hide axes\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2023-07-24T17:45:15.085384Z",
          "iopub.execute_input": "2023-07-24T17:45:15.085879Z",
          "iopub.status.idle": "2023-07-24T17:45:16.247427Z",
          "shell.execute_reply.started": "2023-07-24T17:45:15.085835Z",
          "shell.execute_reply": "2023-07-24T17:45:16.24644Z"
        },
        "trusted": true,
        "id": "Q3obasH5A-8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <div style=\"background-color:#fff1cc; padding: 10px;\">Do upvote if you found this work useful enough. In this notebook we have done Pet's Facial Expression Recognition using a basic CNN architecture.The model currently has less accuracy on test data which can be further improved using other models and techniques\n",
        "\n",
        " </div>"
      ],
      "metadata": {
        "id": "ekJJ8InDA-8h"
      }
    }
  ]
}